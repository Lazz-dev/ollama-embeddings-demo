# 📊 Geração de Embeddings com Ollama

Este projeto demonstra como instalar, configurar e utilizar o [Ollama](https://ollama.com) localmente para gerar vetores de embeddings a partir de um texto simples usando o modelo `nomic-embed-text`.

---

## ✅ Requisitos

- Python 3.8 ou superior
- [Ollama instalado](https://ollama.com/download)
- Modelo `nomic-embed-text` baixado
- Biblioteca `requests` instalada (via pip)

---

## ⚙️ Instalação do Ambiente

1. **Clone este repositório:**

```bash
git clone https://github.com/seu-usuario/ollama-embeddings-demo.git
cd ollama-embeddings-demo
